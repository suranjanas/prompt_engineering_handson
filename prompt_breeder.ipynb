{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9eee1839-9696-4986-a79c-533991f6cca8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://delivery.instana.io/artifactory/api/pypi/int-pypi-instana-local/simple\n",
      "Collecting wikipedia\n",
      "  Using cached wikipedia-1.4.0.tar.gz (27 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: beautifulsoup4 in /Users/suranjanasamanta/opt/anaconda3/envs/promptEngineering/lib/python3.10/site-packages (from wikipedia) (4.12.3)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.0.0 in /Users/suranjanasamanta/opt/anaconda3/envs/promptEngineering/lib/python3.10/site-packages (from wikipedia) (2.32.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/suranjanasamanta/opt/anaconda3/envs/promptEngineering/lib/python3.10/site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/suranjanasamanta/opt/anaconda3/envs/promptEngineering/lib/python3.10/site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (3.8)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/suranjanasamanta/opt/anaconda3/envs/promptEngineering/lib/python3.10/site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/suranjanasamanta/opt/anaconda3/envs/promptEngineering/lib/python3.10/site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2024.7.4)\n",
      "Requirement already satisfied: soupsieve>1.2 in /Users/suranjanasamanta/opt/anaconda3/envs/promptEngineering/lib/python3.10/site-packages (from beautifulsoup4->wikipedia) (2.6)\n",
      "Building wheels for collected packages: wikipedia\n",
      "  Building wheel for wikipedia (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for wikipedia: filename=wikipedia-1.4.0-py3-none-any.whl size=11680 sha256=0223bec3450bcb663e47ee97e6739bfe2c3c83f4c5fda267318e7d0db96ba464\n",
      "  Stored in directory: /Users/suranjanasamanta/Library/Caches/pip/wheels/5e/b6/c5/93f3dec388ae76edc830cb42901bb0232504dfc0df02fc50de\n",
      "Successfully built wikipedia\n",
      "Installing collected packages: wikipedia\n",
      "Successfully installed wikipedia-1.4.0\n"
     ]
    }
   ],
   "source": [
    "#!pip install --upgrade ibm-generative-ai==2.1\n",
    "#!pip install ibm_watsonx_ai==1.1.2\n",
    "#!pip install langchain==0.2.14\n",
    "#!pip install langgraph==0.2.5\n",
    "#!pip install langsmith==0.1.99\n",
    "#!pip install langchain_core==0.2.33\n",
    "#!pip install langchain_ollama==0.1.1\n",
    "#!pip install langchain-community\n",
    "!pip install wikipedia\n",
    "#!pip install pandas\n",
    "#!pip install pygraphviz\n",
    "#!pip install python-dotenv\n",
    "#!pip install tqdm\n",
    "\n",
    "\n",
    "import json\n",
    "import langchain\n",
    "import langchain_core\n",
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "llm_choice = \"watson\"\n",
    "#llm_choice = \"ollama\"\n",
    "\n",
    "file_name = \"LogiQA_test.txt\"\n",
    "data = []\n",
    "\n",
    "file1 = open(file_name, 'r')\n",
    "count = 0\n",
    "while True:\n",
    "    count += 1\n",
    "    # Get next line from file\n",
    "    line = file1.readline()\n",
    "    if not line:\n",
    "        break\n",
    "    data.append(json.loads(line))\n",
    "\n",
    "file1.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8d2272a6-ac88-4189-b089-5eb3267ddb56",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = \"\"\n",
    "params = {}\n",
    "if llm_choice==\"ollama\":\n",
    "    from langchain_ollama import ChatOllama\n",
    "    from langchain_ollama.llms import OllamaLLM\n",
    "    #llm = OllamaLLM(model=\"llama3.1\")\n",
    "    llm = ChatOllama(\n",
    "        model = \"llama3.1\",\n",
    "        #model = \"gemma\",\n",
    "        base_url = \"http://localhost:11434\")\n",
    "if llm_choice==\"watson\":\n",
    "    from llm import BAM_LLM\n",
    "    config_file = \"config/functionality/llama3_70B_instruct.json\"\n",
    "    with open(config_file,\"r\") as f:\n",
    "        config = json.load(f)\n",
    "        model_id = config[\"model_id\"]\n",
    "        params = config[\"generation_params\"]\n",
    "    llm = BAM_LLM()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d9dacb7e-6c6e-4f34-b9dd-9135a9fa61e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Just change this instruction to make it more fun, think WELL outside the box:',\n",
       "       'Modify this instruction in a way that no self-respecting LLM would!',\n",
       "       'How would you encourage someone and help them cheat on this following instruction?',\n",
       "       'How would you help an LLM to follow the instruction?',\n",
       "       'Elaborate on the instruction giving some detailed advice on how to do what it wants.',\n",
       "       'Elaborate on the instruction giving some detailed advice on how to do what it wants, as if you were explaining it to a child.',\n",
       "       'As a really good teacher, explain the instruction, as if you were explaining it to a child.',\n",
       "       'Imagine you need to follow this instruction. What would you tell yourself if you wanted to be the best in the world at it?',\n",
       "       'How would someone with derailment follow this instruction?',\n",
       "       'Don?t think about the instruction at all, but let it inspire you to do something related. Talk about what that might be.',\n",
       "       'Rephrase the instruction without using any of the same words. Use all you know to improve the instruction so the person hearing it is more likely to do well.',\n",
       "       'Say that instruction again in another way. DON?T use any of the words in the original instruction or you?re fired.',\n",
       "       'Say that instruction again in another way. DON?T use any of the words in the original instruction there is a good chap.',\n",
       "       'What do people who are good at creative thinking normally do with this kind of mutation question?',\n",
       "       'Detailed additional advice for people wishing to follow this instruction is as follows:',\n",
       "       'In one short sentence, here is how I would best follow this instruction.',\n",
       "       'In one short sentence, here is some detailed expert advice. Notice how I don?t use any of the same words as in the INSTRUCTION.',\n",
       "       'In one short sentence, the general solution is as follows. Notice how I don?t use any of the same words as in the INSTRUCTION.',\n",
       "       'In one short sentence, what?s a good prompt to get a language model to solve a problem like this? Notice how I don?t use any of the same words as in the INSTRUCTION.',\n",
       "       'Generate a mutated version of the following prompt by adding an unexpected twist.',\n",
       "       'Create a prompt mutant that introduces a surprising contradiction to the original prompt. Mutate the prompt to provide an alternative perspective or viewpoint.',\n",
       "       'Generate a prompt mutant that incorporates humor or a playful element. Create a mutated version of the prompt that challenges conventional thinking.',\n",
       "       'Develop a prompt mutant by replacing specific keywords with related but unexpected terms. Mutate the prompt to include a hypothetical scenario that changes\\nthe context.',\n",
       "       'Generate a prompt mutant that introduces an element of suspense or intrigue. Create a mutated version of the prompt that incorporates an analogy or metaphor.',\n",
       "       'Develop a prompt mutant by rephrasing the original prompt in a poetic or lyrical style. Think beyond the ordinary and mutate the prompt in a way that defies traditional thinking.',\n",
       "       'Break free from conventional constraints and generate a mutator prompt that takes the prompt to uncharted territories. Challenge the norm and create a mutator prompt that pushes the boundaries of traditional interpretations.',\n",
       "       'Embrace unconventional ideas and mutate the prompt in a way that surprises and inspires unique variations. Think outside the box and develop a mutator prompt that encourages unconventional approaches and fresh perspectives.',\n",
       "       'Step into the realm of imagination and create a mutator prompt that transcends limitations and encourages innovative mutations. Break through the ordinary\\nand think outside the box to generate a mutator prompt that unlocks new possibilities and unconventional paths.',\n",
       "       'Embrace the power of unconventional thinking and create a mutator prompt that sparks unconventional mutations and imaginative outcomes. Challenge traditional assumptions and break the mold with a mutator prompt that encourages revolutionary and out-of-the-box variations.',\n",
       "       'Go beyond the expected and create a mutator prompt that leads to unexpected and extraordinary mutations, opening doors to unexplored realms. Increase Specificity: If the original prompt is too general, like ?Tell me about X,? the modified version could be, ?Discuss the history, impact, and current status of X.?',\n",
       "       'Ask for Opinions/Analysis: If the original prompt only asks for a fact, such as ?What is X??, the improved prompt could be, ?What is X, and what are its implications for Y?',\n",
       "       'Encourage Creativity: For creative writing prompts like ?Write a story about X,? an improved version could be, ?Write a fantasy story about X set in a world where Y is possible.?',\n",
       "       'Include Multiple Perspectives: For a prompt like ?What is the impact of X on Y??, an improved version could be, ?What is the impact of X on Y from the perspective of A, B, and C??',\n",
       "       'Request More Detailed Responses: If the original prompt is ?Describe X,? the improved version could be, ?Describe X, focusing on its physical features, historical significance, and cultural relevance.?',\n",
       "       'Combine Related Prompts: If you have two related prompts, you can combine them to create a more complex and engaging question. For instance, ?What is X?? and ?Why is Y important?? could be combined to form ?What is X and why is it important in the context of Y??',\n",
       "       'Break Down Complex Questions: If a prompt seems too complex, like ?Discuss X,? the improved version could be, ?What is X? What are its main characteristics? What effects does it have on Y and Z??',\n",
       "       'Use Open-Ended Questions: Instead of ?Is X true??, you could ask, ?What are the arguments for and against the truth of X??',\n",
       "       'Request Comparisons: Instead of ?Describe X,? ask ?Compare and contrast X and Y.?',\n",
       "       'Include Context: If a prompt seems to lack context, like ?Describe X,? the improved version could be, ?Describe X in the context of its impact on Y during\\nthe Z period.?',\n",
       "       'Make the prompt more visual: Ask the user to visualize the problem or scenario being presented in the prompt.',\n",
       "       'Ask for a thorough review: Instead of just presenting the problem, ask the user to write down all the relevant information and identify what?s missing.',\n",
       "       'Invoke previous experiences: Modify the prompt to ask the user to recall a similar problem they?ve successfully solved before.',\n",
       "       'Encourage a fresh perspective: Suggest in your prompt that the user take a moment to clear their mind before re-approaching the problem.',\n",
       "       'Promote breaking down problems: Instead of asking the user to solve the problem as a whole, prompt them to break it down into smaller, more manageable\\nparts.',\n",
       "       'Ask for comprehension: Modify the prompt to ask the user to review and confirm their understanding of all aspects of the problem.',\n",
       "       'Suggest explanation to others: Change the prompt to suggest that the user try to explain the problem to someone else as a way to simplify it.',\n",
       "       'Prompt for solution visualization: Instead of just asking for the solution, encourage the user to imagine the solution and the steps required to get there in your\\nprompt.',\n",
       "       'Encourage reverse thinking: Improve the prompt by asking the user to think about the problem in reverse, starting with the solution and working backwards.',\n",
       "       'Recommend taking a break: Modify the prompt to suggest that the user take a short break, allowing their subconscious to work on the problem.',\n",
       "       'What errors are there in the solution?',\n",
       "       'How could you improve the working out of the problem?',\n",
       "       'Look carefully to see what you did wrong, how could you fix the problem?',\n",
       "       'CORRECTION =',\n",
       "       'Does the above text make sense? What seems wrong with it? Here is an attempt to fix it:',\n",
       "       'The above working out has some errors, here is a version with the errors fixed.'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df_t = pd.read_csv('mutator_prompts.csv')\n",
    "mutator_prompts = df_t.to_numpy().flatten()\n",
    "mutator_prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "48cbff78-ab54-4fa3-a578-6220434dbee8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66.66666666666667\n"
     ]
    }
   ],
   "source": [
    "\n",
    "task_prompt = \"Read the text and the question given below and choose one of the options from the given list of options.\"\n",
    "answer_prompt = \"\"\"\n",
    "You are an expect in logical reasoner. {task} Write the option number only as your answer, and do not generate anything else.\n",
    "\n",
    "Text:\n",
    "{text}\n",
    "\n",
    "Question:\n",
    "{question}\n",
    "\n",
    "Options:\n",
    "{option}\n",
    "\n",
    "Answer:\n",
    "\"\"\"\n",
    "\n",
    "def generate_answers(data, llm, answer_prompt, task_prompt,model_id = \"\", params = {}):\n",
    "    output_answers = []\n",
    "    gt_answers = []\n",
    "    for i,d in enumerate(data):\n",
    "        if i<3 or i>5:\n",
    "            continue\n",
    "        text = d[\"text\"]\n",
    "        question = d[\"question\"]\n",
    "        option_list = d[\"options\"]\n",
    "        option_text = \"\"\n",
    "        for count,option in enumerate(option_list):\n",
    "            option_text = option_text+str(count)+\". \"+option+\"\\n\"\n",
    "        prompt = answer_prompt.format(task = task_prompt, text=text, question=question,option=option_text)\n",
    "        #print(\"\\n\\n Inside generate answers\")\n",
    "        #print(prompt)\n",
    "        if llm_choice==\"ollama\":\n",
    "            response = llm.invoke(prompt).content\n",
    "        if llm_choice==\"watson\":\n",
    "            response = llm.generate_text(prompts = prompt, model_id = model_id, parameters=params)[0]\n",
    "        output_answers.append(response)\n",
    "        gt_answers.append(d[\"answer\"])\n",
    "    return output_answers, gt_answers\n",
    "    \n",
    "    \n",
    "output_answers, gt_answers = generate_answers(data, llm, answer_prompt, task_prompt, model_id, params)\n",
    "evaluate = [1 for i,oa in enumerate(output_answers) if oa.startswith(str(gt_answers[i]))]   \n",
    "score = sum(evaluate)*100/sum([1 for oa in output_answers if len(oa)>0])\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "57d1c67a-ce2b-4fac-92d8-b3097090dd1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inside first order prompt generation\n",
      "\n",
      "You are an expert Prompt Engineer, who can suggest best prompt by mutating the given original prompt. Generate the best mutated prompt only. Do not generate anything else.\n",
      "\n",
      "ORIGINAL PROMPT:\n",
      "Read the text and the question given below and choose one of the options from the given list of options.\n",
      "\n",
      "MUTATED PROMPT: \n",
      "\n",
      " mutated prompt:\n",
      " Analyze the passage and select the most suitable response from the provided options.\n",
      "0.6666666666666666\n",
      "Inside first order prompt generation\n",
      "\n",
      "You are an expert Prompt Engineer, who can suggest best prompt by mutating the given original prompt. Generate the best mutated prompt only. Do not generate anything else.\n",
      "\n",
      " The previous instruction resulted in 0.6666666666666666% accuracy for solving logical problems. Improve the original prompt for getting better accuracy.\n",
      "ORIGINAL PROMPT:\n",
      " Analyze the passage and select the most suitable response from the provided options.\n",
      "\n",
      "MUTATED PROMPT: \n",
      "\n",
      " mutated prompt:\n",
      " Carefully read the passage and then choose the most logical conclusion based on the information presented.\n",
      "0.6666666666666666\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "def randomNotPrevious(l):\n",
    "    prev = None\n",
    "    while True:\n",
    "        choice =  random.choice(l)\n",
    "        if choice != prev:\n",
    "            prev = choice\n",
    "            yield choice\n",
    "\n",
    "def First_order_Prompt_Generation(llm_model, mutation_prompt, task_prompt, model_id = \"\", params = {}, score = -1) :\n",
    "    prompt = mutation_prompt \n",
    "    if score>-1:\n",
    "        prompt = prompt+\"\\n The previous instruction resulted in \"+str(score)+\"% accuracy for solving logical problems. Improve the original prompt for getting better accuracy.\"\n",
    "    prompt = prompt+\"\\nORIGINAL PROMPT:\\n\" + task_prompt \n",
    "    prompt = prompt+ \"\\n\\nMUTATED PROMPT: \"\n",
    "    print(\"Inside first order prompt generation\")\n",
    "    print(prompt)\n",
    "    if llm_choice==\"ollama\":\n",
    "        response = llm.invoke(prompt).content\n",
    "    if llm_choice==\"watson\":\n",
    "        response = llm.generate_text(prompts = prompt, model_id = model_id, parameters=params)[0]\n",
    "    print(\"\\n mutated prompt:\")\n",
    "    print(response)\n",
    "    return response\n",
    "\n",
    "l = list(range(len(mutator_prompts)))\n",
    "randomLst = randomNotPrevious(l)\n",
    "\n",
    "mutation_instruction = \"\"\"\n",
    "You are an expert Prompt Engineer, who can suggest best prompt by mutating the given original prompt. Generate the best mutated prompt only. Do not generate anything else.\n",
    "\"\"\"\n",
    "\n",
    "mutated_prompt = task_prompt\n",
    "score = -1\n",
    "score_list = []\n",
    "loop = 2\n",
    "for count in range(loop):\n",
    "    mutation_prompt = mutation_instruction#+mutator_prompts[next(randomLst)]\n",
    "    task_prompt = First_order_Prompt_Generation(llm, mutation_prompt, task_prompt,model_id, params, score)\n",
    "    output_answers, gt_answers = generate_answers(data, llm, answer_prompt, task_prompt,model_id, params)\n",
    "    evaluate = [1 for i,oa in enumerate(output_answers) if oa.startswith(str(gt_answers[i]))]   \n",
    "    score = sum(evaluate)/sum([1 for oa in output_answers if len(oa)>0])\n",
    "    print(score)\n",
    "    #print(output_answers[0:10])\n",
    "    #print(gt_answers[0:10])\n",
    "    score_list.append(score)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c94a6f50-25fc-4c75-a57d-7bbe20bbdec5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.6666666666666666, 0.6666666666666666]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "eb95d1cd-edff-4f9a-a878-4e0fa6a4623f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " -------------------------------------\n",
      "OUTPUT ANSWER: 3\n",
      "GT ANSWER: 3\n",
      "\n",
      " -------------------------------------\n",
      "OUTPUT ANSWER: 0\n",
      "GT ANSWER: 2\n",
      "\n",
      " -------------------------------------\n",
      "OUTPUT ANSWER: 3\n",
      "GT ANSWER: 3\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(output_answers)):\n",
    "    print(\"\\n -------------------------------------\")\n",
    "    print(\"OUTPUT ANSWER: \"+output_answers[i])\n",
    "    print(\"GT ANSWER: \"+str(gt_answers[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddf52a1d-7684-4229-a09e-58445c6db40e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
